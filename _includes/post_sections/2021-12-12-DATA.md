<!-- ---
layout: post
title: "Data"
# subtitle: "because they lacked opposable thumbs and the brainpower to build a space program."
background: '/img/gender-data-gap-davos.jpg'
--- -->

## Primary dataset - [Quotebank](https://quotebank.dlab.tools/)

<div style="text-align: justify"> While the original dataset stems from Quotebank and spans comprehensively the English-speaking media world from 2012 to early 2020, for the subsequent analysis we trimmed it down to quotes originating from US media. Furthermore, not all quotes had identified speakers, making it impossible to determine their gender further reducing our starting dataset.
</div>

## Enhanced dataset

<div style="text-align: justify"> But then, we had a quite boring dataset not suited to go on an ADAventure into the US media landscape. Beyond the wikilinks to the identified speakers, which were already part of Quotebank, there was not much to explore. Thus we expanded the horizons of our dataset by first of all linking it to the glorious online resource [Media Bias Fact Check](https://mediabiasfactcheck.com/), that provided us exactly with what we needed: They are a comprehensive database of a majority of English speaking (and an even larger portion of American media) and both classify them on their country of origin, factual reporting, their political bias (left-leaning, right-leaning) and the traffic of the respective media webpage. The methodology can be found [here](https://mediabiasfactcheck.com/methodology/).

We subsequently selected all the US media with high traffic since our goal is to investigate mainstream female representation consumed most broadly. Thanks to the binary political structure, we also have a relatively balanced subdataset (see graphs) for media classified as either left- or right-leaning. 

Furthermore, as we are also interested in female representation behind the scenes and according to studies, the situation in the US media landscape is dire [(find an executive summary on female chief editors)](https://womensmediacenter.com/reports/the-status-of-women-in-u-s-media-2019), so we set out to see for ourselves and annotated the approximately 150 highest traffic online media by hand with the current editor-in-chief and their respective gender. This allowed to make very telling statistics that you can explore [here](https://vfayt99.github.io/femedia/2021/01/02/Analysis.html).

As a last step, we then used the wikidata handles to the speakers in the original quotebank to extract the gender of all the quotes we had preselected by the above procedure to obtain our dataset if interest.

Furthermore, to obtain the final datasata amenable for topic analysis we used uniform random sampling across the above formed dataset to obtain a smaller datasize for this task. For equal presentation of the years, the same number of quotes per year were sampled (250 000) rather than percentual. For our topic analyses on the quotes we run an the Gibbs Sampling Dirichlet Multinomial Mixture algorithm - which is the less efficient little sister of LDA - but has shown better results for short text topic analyses with one topic per text sample, as it is most likely the case for quotes appearing in media. [Background info on GSDMM](https://towardsdatascience.com/short-text-topic-modelling-lda-vs-gsdmm-20f1db742e14).
</div>

<br><br>

- OVerview media, ratio of female quotes in media with info on right/left bias
<iframe width="100%" height="800" frameborder="0" scrolling="no" src="//plotly.com/~VFayt99/18.embed"></iframe>

<br>
<!-- <iframe  width = "100%" height= "300" frameborder="0" scrolling="no" src="//plotly.com/~VFayt99/6.embed"></iframe> -->

<!-- <iframe width="900" height="800" frameborder="0" scrolling="no" src="//plotly.com/~VFayt99/3.embed"></iframe> -->
