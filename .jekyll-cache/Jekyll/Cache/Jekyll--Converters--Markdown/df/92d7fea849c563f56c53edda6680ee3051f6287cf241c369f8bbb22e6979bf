I"ï<!-- ---
layout: post
title: "DATA"
# subtitle: "because they lacked opposable thumbs and the brainpower to build a space program."
background: '/img/gender-data-gap-davos.jpg'
--- -->

<h2 id="primary-dataset---quotebank">Primary dataset - <a href="https://quotebank.dlab.tools/">Quotebank</a></h2>

<p>While the original dataset stems from Quotebank and spans comprehensively the English-speaking media world from 2012 to early 2020, for the subsequent analysis we trimmed it down to quotes originating from US media. Furthermore, not all quotes had identified speakers, making it impossible to determine their gender further reducing our starting dataset.</p>

<h2 id="enhanced-dataset">Enhanced dataset</h2>

<p>But then, we had a quite boring dataset not suited to go on an ADAventure into the US media landscape. Beyond the wikilinks to the identified speakers, which were already part of Quotebank, there was not much to explore. Thus we expanded the horizons of our dataset by first of all linking it to the glorious online resource <a href="https://mediabiasfactcheck.com/">Media Bias / Fact Check</a>, that provided us exactly with what we needed: They are a comprehensive database of a majority of English speaking (and an even larger portion of American media) and both classify them on their country of origin, factual reporting, their political bias (left-leaning, right-leaning) and the traffic of the respective media webpage. The methodology can be found <a href="https://mediabiasfactcheck.com/methodology/">here</a>.</p>

<p>We subsequently selected all the US media with high traffic since our goal is to investigate mainstream female representation consumed most broadly. Thanks to the binary political structure, we also have a relatively balanced subdataset (see graphs) for media classified as either left- or right-leaning.</p>

<p>Furthermore, as we are also interested in female representation behind the scenes and according to studies, the situation in the US media landscape is dire <a href="https://womensmediacenter.com/reports/the-status-of-women-in-u-s-media-2019">(find an executive summary on female chief editors)</a>, so we set out to see for ourselves and annotated the approximately 150 highest traffic online media by hand with the current editor-in-chief and their respective gender. This allowed to make very telling statistics that you can explore [here] LINK TO OUR STATISTICS PAGE.</p>

<p>As a last step, we then used the wikidata handles to the speakers in the original quotebank to extract the gender of all the quotes we had preselected by the above procedure to obtain our final dataset.</p>

<p>Well, almost final: For our topic analyses on the quotes we run an the Gibbs Sampling Dirichlet Multinomial Mixture algorithm - which is the less efficient little sister of LDA - but necessary for short text topic analyses as the condition that multiple topics are present is not met in a ‚Äúone-sentence text‚Äù. <a href="https://towardsdatascience.com/short-text-topic-modelling-lda-vs-gsdmm-20f1db742e14">background info on GSDMM</a> That means we have to resort to uniform random sampling across the above formed dataset to obtain handleable datasize for this task.</p>
:ET